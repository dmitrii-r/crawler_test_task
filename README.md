# crawler_test_task

Стек: Python3, aiogram, pandas, sqlite3

## Описание бота
Представьте, что у вас есть система без интерфейса пользователя, например crawler (сборщик
информации), который парсит все сайты по продаже зюзюбликов и сохраняет в базу данных.

Появилась потребность дать обычному пользователю минимальными усилиями добавлять еще
сайты для парсинга

Напишите простого бота, который будет иметь одну кнопку: загрузить файл

1. При нажатии кнопки пользователь прикрепляет файл excel в формате таблицы с
полями:
   - title - название
   - url - ссылка на сайт источник
   - xpath - путь к элементу с ценой
2. Бот получает файл, сохраняет
3. Открывает файл библиотекой pandas
4. Выводит содержимое в ответ пользователю
5. Сохраняет содержимое в локальную БД sqlite

## Запуск бота на локальном хранилище

Клонируйте репозиторий и перейдите в него:
```
git clone https://github.com/dmitrii-r/crawler_test_task.git
```
```
cd crawler_test_task
```
Cоздайте и активируйте виртуальное окружение:
```
python3 -m venv env
```
```
source env/bin/activate
```
Обновите установщик пакетов PIP:
```
python3 -m pip install --upgrade pip
```
Установите зависимости из файла requirements.txt:
```
pip install -r requirements.txt
```
Создайте файл .env и заполните его по образцу .env.example.
Запустите исполняемый файл бота:
```
python3 bot.py
```

## Запуск бота на удаленном сервере

Клонируйте репозиторий:
```
git clone https://github.com/dmitrii-r/crawler_test_task.git
```
Перейдите в директорию с клонированным репозиторием:
```
cd crawler_test_task
```
Создайте файл .env и заполните его по образцу .env.example.
Перейдите в директорию infra и запустите контейнеры:
```
cd infra
```
```
docker-compose up -d
```